{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100dayschallengesTF1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "qk01c8Ddsvhz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Dataset and preprocessing data**"
      ],
      "metadata": {
        "id": "3PcPFROqxj71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading fashion mnist dataset available in keras dataset\n",
        "(x_train, y_train), (x_test, y_test)= fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "UTCS4x0Bt6rD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training example: \", x_train.shape[0], \"and is of dimension\", (x_train.shape[1], x_train.shape[2]))\n",
        "print(\"Testing example: \", x_test.shape[0], \"and is of dimension\", (x_test.shape[1], x_test.shape[2]))\n",
        "print(\"The total classes for classification of fashion mnist dataset is: \", len(np.unique(y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UQSP597s10C",
        "outputId": "e0301aa8-b5e0-4dcc-849e-aab391e7d95b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training example:  60000 and is of dimension (28, 28)\n",
            "Testing example:  10000 and is of dimension (28, 28)\n",
            "The total classes for classification of fashion mnist dataset is:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We know that image is of 28*28 pixel, i.e. 2-dimesionional, but our neural network takes an array of a single dimensional vector.\n",
        "#so we convert 2-d images into 1-d vector i.e 1*784\n",
        "x_train= x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
        "x_test= x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])"
      ],
      "metadata": {
        "id": "y9dbr_IJoAMe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizing the data before passing it to the neural network\n",
        "x_train= x_train/255\n",
        "x_test= x_test/255"
      ],
      "metadata": {
        "id": "9egYUHvrtD6S"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since our total number of category to be classified is 10, so converting output i.e y_train into a 10-D vector\n",
        "\n",
        "#before converting\n",
        "print(\"The output category of 1st training example is:\", y_train[0])\n",
        "\n",
        "#converting into 10-D vector by passing parameters-->output list, number of dimension\n",
        "# Note: The 2nd parameter in \"to_categorical\" function should contain the dimension which is equal to no. of classes  of output labels  \n",
        "y_train= utils.to_categorical(y_train, 10)\n",
        "y_test= utils.to_categorical(y_test, 10)\n",
        "\n",
        "#after converting \n",
        "print(\"The output category of 1st training example is:\", y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApkTvD1xtE3w",
        "outputId": "cc8575eb-3838-4b7f-802a-0c51d9032a0c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output category of 1st training example is: 9\n",
            "The output category of 1st training example is: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building**"
      ],
      "metadata": {
        "id": "dBBdjJE9xuSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining parameters for building our model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "#x_train.shape --> (60000, 784)\n",
        "input_dim= x_train.shape[1]\n",
        "output_dim= 10\n",
        "batch_size= 128\n",
        "nb_epoch= 20"
      ],
      "metadata": {
        "id": "EaR8n4qItVOh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building a multilayer Perceptron(MLP)\n",
        "model= Sequential()\n",
        "#Adding multiple fully connected dense layer \n",
        "model.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
        "model.add(Dense(128, activation= 'sigmoid'))\n",
        "model.add(Dense(output_dim, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "#The parameter is calculated as below:\n",
        "#input_dim(784)* 512 + bias_vector(512)==> 401920\n",
        "# Similarly in dense_1 ==> (512* 128)+ 128==> 65664\n",
        "#In dense_2 ==> (128* 10)+ 10 ==> 1290"
      ],
      "metadata": {
        "id": "ZKI47pMA0Xvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e519f994-c0b3-408d-e903-b77cc3d808a2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 468,874\n",
            "Trainable params: 468,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In model.compile we pass three main parameters. i.e optimizer, loss, and metrics.\n",
        "\n",
        "#Optimizer is an algorithm that modifies the attributes of out NN, such as weights and \n",
        "# learning rate.Thus, it helps in reducing the overall loss and improve the accuracy.\n",
        "\n",
        "#Loss: This is the objective function that the model will try to minimize.\n",
        "\n",
        "#metrics: It defines how accurate our model is. For classification task we\n",
        "#generally use 'accuracy' as evaluating metric.(There are other methods like 'confusion matrix' for assessing our model)\n",
        "\n",
        "#The actual training is performed by 'model.fit' which is used to train our neural network\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model= model.fit(x_train, y_train, batch_size= batch_size, epochs= nb_epoch, verbose=1, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvYUEF9tuIWQ",
        "outputId": "b7eaa9ba-e2dc-4444-a6c1-b1fc311cd9cd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 6s 10ms/step - loss: 2.2248 - accuracy: 0.3338 - val_loss: 2.1269 - val_accuracy: 0.5118\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.9997 - accuracy: 0.5411 - val_loss: 1.8548 - val_accuracy: 0.5705\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.6949 - accuracy: 0.5815 - val_loss: 1.5469 - val_accuracy: 0.6095\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.4253 - accuracy: 0.6229 - val_loss: 1.3259 - val_accuracy: 0.6445\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 1.2442 - accuracy: 0.6586 - val_loss: 1.1804 - val_accuracy: 0.6764\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.1206 - accuracy: 0.6842 - val_loss: 1.0789 - val_accuracy: 0.6721\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.0294 - accuracy: 0.7000 - val_loss: 0.9980 - val_accuracy: 0.6981\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.9580 - accuracy: 0.7117 - val_loss: 0.9358 - val_accuracy: 0.7135\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.9000 - accuracy: 0.7218 - val_loss: 0.8846 - val_accuracy: 0.7176\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.8525 - accuracy: 0.7281 - val_loss: 0.8416 - val_accuracy: 0.7201\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.8132 - accuracy: 0.7324 - val_loss: 0.8073 - val_accuracy: 0.7302\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7810 - accuracy: 0.7364 - val_loss: 0.7787 - val_accuracy: 0.7318\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7543 - accuracy: 0.7401 - val_loss: 0.7551 - val_accuracy: 0.7334\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7319 - accuracy: 0.7431 - val_loss: 0.7353 - val_accuracy: 0.7371\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7131 - accuracy: 0.7464 - val_loss: 0.7184 - val_accuracy: 0.7431\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6972 - accuracy: 0.7492 - val_loss: 0.7040 - val_accuracy: 0.7453\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6834 - accuracy: 0.7526 - val_loss: 0.6911 - val_accuracy: 0.7508\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6712 - accuracy: 0.7564 - val_loss: 0.6798 - val_accuracy: 0.7531\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6601 - accuracy: 0.7597 - val_loss: 0.6703 - val_accuracy: 0.7573\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6503 - accuracy: 0.7624 - val_loss: 0.6608 - val_accuracy: 0.7587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Score is the evaluation of the loss function for a given input.The lower the loss/score, the better a model\n",
        "#Accuracy: For example, if the number of test samples is 1000 and model classifies 950 of those correctly, then the model's accuracy is 95%.\n",
        "accuracy= (model.history['accuracy'])[-1]\n",
        "score= (model.history['loss'])[-1]\n",
        "print('Train score:', accuracy) \n",
        "print('Train accuracy:', score)"
      ],
      "metadata": {
        "id": "IkA6rMO-uKlf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3517e49c-abfb-4f0d-8ee8-ac7757984481"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.7624333500862122\n",
            "Train accuracy: 0.6503081321716309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pG34pltT6JOo"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IGWSqLzi7Vbo"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1BWIGuXZ9cnK"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CzzMN00y9psr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}